---
title: "Water Potability"
author: "Alicia Key"
date: "2022-08-12"
output: html_document
---

# Water potability modeling

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Required libraries and random seed

### Required libraries

```{r}
library(readr)
library(dplyr)
library(tidyr)
library(forcats)
library(ggplot2)
library(rsample)
library(parsnip)
library(yardstick)
library(broom)
library(ggplot2)
library(tune)
library(recipes)
library(workflows)
library(dials)
library(xgboost)
```

### Random seed

```{r}
set.seed(123)
```

## Initial data load

```{r}
water <- read_csv("data/water_potability.csv")
knitr::kable(head(water))
```

## Feature engineering

### Visualizing number of missing values.

Modified from [https://towardsdatascience.com/missing-value-visualization-with-tidyverse-in-r-a9b0fefd2246](https://towardsdatascience.com/missing-value-visualization-with-tidyverse-in-r-a9b0fefd2246)

```{r}
water_total_rows = nrow(water)

water_missing <- water %>%
  pivot_longer(everything(), names_to = "name", values_to = "value") %>%
  mutate(is_missing = is.na(value)) %>%
  group_by(name, is_missing) %>%
  summarize(num_missing = n()) %>%
  filter(is_missing) %>%
  transmute(
    percent_missing = num_missing / water_total_rows * 100
  ) %>%
  rename(variable = name) %>%
  arrange(desc(percent_missing))

knitr::kable(water_missing)
```

```{r}
ggplot(water_missing, aes(x = variable, y = percent_missing)) +
  geom_col()
```

### Turn potability into a factor

Call the factor `potable`. The event of interest, potable water, is the first level of the factor.

```{r}
water_2 <- water %>%
  mutate(potable = factor(
      case_when(
        Potability == 0 ~ "not_potable",
        Potability == 1 ~ "potable"
      ),
      levels = c("potable", "not_potable")
    )
  ) %>%
  select(-Potability)

knitr::kable(head(water_2))
```

### Train test split

```{r}
water_split <- initial_split(water_2, prop = 0.75, strata = potable)
water_train <- training(water_split)
```

### Recipe to preprocess data and fill missing values

- Handle missing values with kNN

```{r}
clean_water_recipe <- recipe(potable ~ ., data = water_train) %>%
  step_impute_knn(all_numeric(), neighbors = 10)
```

## Exploratory visualization

First, get a copy of the *all* data with the missing values filled in to use in the visualizations.

```{r}
clean_water <- clean_water_recipe %>%
  prep(training = water_train) %>%
  bake(new_data = water_2)
```

### How many observations are in class?

There are many more observations that are not potable.

```{r}
clean_water_class_count <- clean_water %>%
  group_by(potable) %>%
  summarize(class_count = n())

knitr::kable(clean_water_class_count)
```

```{r}
ggplot(clean_water_class_count, aes(x = potable, y = class_count)) +
  geom_col() +
  ggtitle("Class count in entire dataset")
```

### Distributions variables depending on potability

```{r}
ggplot(clean_water, aes(x = potable, y = ph)) +
  geom_violin() +
  ggtitle("pH")
```

```{r}
ggplot(clean_water, aes(x = potable, y = Hardness)) +
  geom_violin() +
  ggtitle("Hardness")
```

```{r}
ggplot(clean_water, aes(x = potable, y = Solids)) +
  geom_violin() +
  ggtitle("Solids")
```

```{r}
ggplot(clean_water, aes(x = potable, y = Chloramines)) +
  geom_violin() +
  ggtitle("Chloramines")
```

```{r}
ggplot(clean_water, aes(x = potable, y = Sulfate)) +
  geom_violin() +
  ggtitle("Sulfate")
```

```{r}
ggplot(clean_water, aes(x = potable, y = Conductivity)) +
  geom_violin() +
  ggtitle("Conductivity")
```

```{r}
ggplot(clean_water, aes(x = potable, y = Organic_carbon)) +
  geom_violin() +
  ggtitle("Organic Carbon")
```

```{r}
ggplot(clean_water, aes(x = potable, y = Trihalomethanes)) +
  geom_violin() +
  ggtitle("Trihalomethanes")
```

```{r}
ggplot(clean_water, aes(x = potable, y = Turbidity)) +
  geom_violin() +
  ggtitle("Turbidity")
```

## k-fold cross validation

```{r}
water_folds <- vfold_cv(water_train, v = 20, strata = potable)
```

## Logistic regression

First, I will start with a basic logistic regression as a baseline.

### Create and fit the logistic model

```{r}
logistic_model <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

logistic_last_fit <- logistic_model %>%
  last_fit(potable ~ ., split = water_split)
```

### Evaluate logistic performance

```{r}
logistic_last_fit_metrics <- logistic_last_fit %>%
  collect_metrics()

logistic_last_fit_roc_auc <- logistic_last_fit_metrics %>%
  filter(.metric == "roc_auc") %>%
  pull(.estimate)

knitr::kable(logistic_last_fit_metrics)
```

```{r}
logistic_last_fit_results <- logistic_last_fit %>%
  collect_predictions()

logistic_last_fit_results %>%
  roc_curve(truth = potable, .pred_potable) %>%
  autoplot()
```
## Decision tree

### Decision tree workflow and grid

```{r}
decision_tree_model <- decision_tree(
    cost_complexity = tune(),
    tree_depth = tune(),
    min_n = tune()
  ) %>%
  set_engine("rpart") %>%
  set_mode("classification")

decision_tree_workflow <- workflow() %>%
  add_model(decision_tree_model) %>%
  add_recipe(clean_water_recipe)

decision_tree_grid <- grid_random(parameters(decision_tree_model), size = 10)
```

### Tune the decision tree

```{r}
doParallel::registerDoParallel()

decision_tree_tuning <- decision_tree_workflow %>%
  tune_grid(
    resamples = water_folds,
    grid = decision_tree_grid,
    metrics = metric_set(roc_auc, sens, spec)
  )
```

### Fit the best decision tree

```{r}
best_decision_tree_model <- decision_tree_tuning %>%
  select_best(metric = "roc_auc")

final_decision_tree_workflow <- decision_tree_workflow %>%
  finalize_workflow(best_decision_tree_model)

decision_tree_final_fit <- final_decision_tree_workflow %>%
  last_fit(split = water_split)
```

### Final decision tree assesment

The decision tree ROC AUC of 0.62 is not good. It is barely better than a coin toss!

```{r}
decision_tree_final_fit_metrics <- decision_tree_final_fit %>%
  collect_metrics()

decision_tree_final_fit_roc_auc <- decision_tree_final_fit_metrics %>%
  filter(.metric == "roc_auc") %>%
  pull(.estimate)
  
knitr::kable(decision_tree_final_fit_metrics)
```

```{r}
decision_tree_final_fit %>%
  collect_predictions() %>%
  roc_curve(truth = potable, .pred_potable) %>%
  autoplot()
```

## xgboost

Define the model and the workflow to go with it.

```{r}
xgboost_model <- 
  boost_tree(
    trees = tune(), 
    min_n = tune(), 
    tree_depth = tune(), 
    learn_rate = tune(), 
    loss_reduction = tune(), 
    sample_size = tune()
  ) %>% 
  set_mode("classification") %>% 
  set_engine("xgboost")

xgboost_workflow <- 
  workflow() %>% 
  add_recipe(clean_water_recipe) %>% 
  add_model(xgboost_model)

xgboost_grid <- grid_random(parameters(xgboost_model), size = 10)
```

### Tune the xgboost

```{r}
doParallel::registerDoParallel()

xgboost_tuning <- xgboost_workflow %>%
  tune_grid(
    resamples = water_folds,
    grid = xgboost_grid,
    metrics = metric_set(roc_auc, sens, spec)
  )
```

### Finalize the best xgboost

```{r}
best_xgboost_model <- xgboost_tuning %>%
  select_best(metric = "roc_auc")

final_xgboost_workflow <- xgboost_workflow %>%
  finalize_workflow(best_xgboost_model)

xgboost_final_fit <- final_xgboost_workflow %>%
  last_fit(split = water_split)
```

### Final xgboost assesment

An ROC AUC of 0.66 is better than the decision tree's 0.62, but not by much, unfortunately.

```{r}
xgboost_final_fit_metrics <- xgboost_final_fit %>%
  collect_metrics()

xgboost_final_fit_roc_auc <- xgboost_final_fit_metrics %>%
  filter(.metric == "roc_auc") %>%
  pull(.estimate)

knitr::kable(xgboost_final_fit_metrics)
```

```{r}
xgboost_final_fit %>%
  collect_predictions() %>%
  roc_curve(truth = potable, .pred_potable) %>%
  autoplot()
```

## Final comparison

### Plot of AUC_ROC for xgboost and decision tree

```{r}
comparison <- tibble(
    model = factor(
      c("xgboost", "decision tree", "logistic"),
      levels = c("xgboost", "decision tree", "logistic")
    ),
    roc_auc = c(
      xgboost_final_fit_roc_auc, 
      decision_tree_final_fit_roc_auc,
      logistic_last_fit_roc_auc
    )
  ) %>%
  arrange(desc(roc_auc))

knitr::kable(comparison)
```

```{r}
ggplot(comparison, aes(x = model, y = roc_auc)) +
  geom_col() +
  ggtitle("Comparison of xgboost and decision tree ROC AUC metrics") +
  labs(y = "ROC AUC")
```
