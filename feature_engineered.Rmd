---
title: "Water Potability"
author: "Alicia Key"
date: "2022-08-12"
output: html_document
---

# Water potability modeling

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Required libraries and random seed

### Required libraries

```{r}
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(rsample)
library(parsnip)
library(yardstick)
library(broom)
library(ggplot2)
library(tune)
library(recipes)
library(workflows)
library(dials)
```

### Random seed

```{r}
set.seed(123)
```

## Initial data load

```{r}
water <- read_csv("data/water_potability.csv")
knitr::kable(head(water))
```

## Feature engineering

### Visualizing number of missing values.

Modified from [https://towardsdatascience.com/missing-value-visualization-with-tidyverse-in-r-a9b0fefd2246](https://towardsdatascience.com/missing-value-visualization-with-tidyverse-in-r-a9b0fefd2246)

```{r}
water_total_rows = nrow(water)

water_missing <- water %>%
  pivot_longer(everything(), names_to = "name", values_to = "value") %>%
  mutate(is_missing = is.na(value)) %>%
  group_by(name, is_missing) %>%
  summarize(num_missing = n()) %>%
  filter(is_missing) %>%
  transmute(
    percent_missing = num_missing / water_total_rows * 100
  ) %>%
  rename(variable = name) %>%
  arrange(desc(percent_missing))

knitr::kable(water_missing)
```

```{r}
ggplot(water_missing, aes(x = variable, y = percent_missing)) +
  geom_col()
```

### Turn potability into a factor

Call the factor `potable`. The event of interest, potable water, is the first level of the factor.

```{r}
water_2 <- water %>%
  mutate(potable = factor(
      case_when(
        Potability == 0 ~ "not_potable",
        Potability == 1 ~ "potable"
      ),
      levels = c("potable", "not_potable")
    )
  ) %>%
  select(-Potability)

knitr::kable(head(water_2))
```

### Train test split

```{r}
water_split <- initial_split(water_2, prop = 0.75, strata = potable)
water_train <- training(water_split)
water_test <- testing(water_split)
```

### Recipe to preprocess values

- Handle missing values with kNN

```{r}
clean_water_recipe <- recipe(potable ~ ., data = water_train) %>%
  step_impute_knn(all_numeric(), neighbors = 10)
```

## Tuned decision tree

### k-fold cross validation

```{r}
water_folds <- vfold_cv(water_train, v = 20, strata = potable)
```

### Decision tree workflow and grid

```{r}
decision_tree_model <- decision_tree(
    cost_complexity = tune(),
    tree_depth = tune(),
    min_n = tune()
  ) %>%
  set_engine("rpart") %>%
  set_mode("classification")

decision_tree_workflow <- workflow() %>%
  add_model(decision_tree_model) %>%
  add_recipe(clean_water_recipe)

decision_tree_grid <- grid_random(parameters(decision_tree_model), size = 20)
```

### Tune the model

```{r}
doParallel::registerDoParallel()

decision_tree_tuning <- decision_tree_workflow %>%
  tune_grid(
    resamples = water_folds,
    grid = decision_tree_grid,
    metrics = metric_set(roc_auc, sens, spec)
  )
```

### Fit the best model

```{r}
best_decision_tree_model <- decision_tree_tuning %>%
  select_best(metric = "sens")

final_decision_tree_workflow <- decision_tree_workflow %>%
  finalize_workflow(best_decision_tree_model)

decision_tree_final_fit <- final_decision_tree_workflow %>%
  last_fit(split = water_split)
```

### Final decision tree model assesment

```{r}
decision_tree_final_fit %>%
  collect_metrics()
```

### Final ROC curve

Not too great...an ROC AUC of 0.59 is barely better than a coin toss.

```{r}
decision_tree_final_fit %>%
  collect_predictions() %>%
  roc_curve(truth = potable, .pred_potable) %>%
  autoplot()
```

